#!/usr/bin/env python3
"""
ç»Ÿä¸€æ¨¡å‹è®­ç»ƒè„šæœ¬ - Train All Models

è¯¥è„šæœ¬ç”¨äºç»Ÿä¸€è®­ç»ƒæ‰€æœ‰ç‘œä¼½å§¿åŠ¿ç›¸å…³çš„æ¨¡å‹ï¼š
1. è¯„åˆ†æ¨¡å‹ï¼ˆScore Modelï¼‰
2. åˆ†ç±»æ¨¡å‹ï¼ˆClassification Modelï¼‰
3. è§†é¢‘æ¨¡å‹ï¼ˆVideo Model - é¢„ç•™ï¼‰

Usage:
    python train_all.py
"""

import os
import sys
import subprocess
from datetime import datetime
from pathlib import Path

# è®¾ç½®æ—¥å¿—ç›®å½•
LOG_DIR = Path("logs/train_all")
LOG_DIR.mkdir(parents=True, exist_ok=True)
LOG_FILE = LOG_DIR / f"train_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

# å¯¼å…¥è¯„åˆ†æ¨¡å‹è®­ç»ƒå‡½æ•°
try:
    from train_model import train_from_dataset
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šæ— æ³•å¯¼å…¥ train_model æ¨¡å—")
    train_from_dataset = None


class TeeOutput:
    """åŒæ—¶è¾“å‡ºåˆ°ç»ˆç«¯å’Œæ–‡ä»¶çš„ç±»"""
    def __init__(self, file_path):
        self.terminal = sys.stdout
        self.log = open(file_path, 'w', encoding='utf-8')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
        self.log.flush()
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
    
    def close(self):
        self.log.close()


# è®¾ç½®åŒé‡è¾“å‡º
tee = TeeOutput(LOG_FILE)
sys.stdout = tee


def train_classifier_model(input_dir="dataset/classify", 
                         output_model="models/classify/classify_model.h5",
                         output_labels="models/classify/class_labels.txt",
                         epochs=15, batch_size=32):
    """
    è°ƒç”¨åˆ†ç±»æ¨¡å‹è®­ç»ƒè„šæœ¬
    
    ç”±äº train_classifier.py æ²¡æœ‰å¯¼å‡ºå‡½æ•°ï¼Œä½¿ç”¨ subprocess è°ƒç”¨
    
    æ³¨æ„ï¼štrain_classifier.py å½“å‰å¯èƒ½ä¸æ”¯æŒå‘½ä»¤è¡Œå‚æ•°ã€‚
    å¦‚éœ€å‚æ•°ç”Ÿæ•ˆï¼Œè¯·åœ¨ train_classifier.py ä¸­æ·»åŠ  argparse æ”¯æŒã€‚
    """
    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {input_dir}")
    print(f"ğŸ’¾ è¾“å‡ºæ¨¡å‹: {output_model}")
    print(f"ğŸ·ï¸ æ ‡ç­¾æ–‡ä»¶: {output_labels}")
    print(f"ğŸ”„ è®­ç»ƒè½®æ•°: {epochs}")
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_model), exist_ok=True)
    
    # æ„å»ºå‘½ä»¤ï¼Œä¼ é€’å‚æ•°
    # æ³¨ï¼šå¦‚æœ train_classifier.py ä¸æ”¯æŒè¿™äº›å‚æ•°ï¼Œå®ƒä»¬ä¼šè¢«å¿½ç•¥
    cmd = [
        sys.executable, "scripts/train_classifier.py",
        "--epochs", str(epochs),
        "--batch-size", str(batch_size)
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode == 0:
        print("âœ… åˆ†ç±»æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        print(f"   æ¨¡å‹å·²ä¿å­˜è‡³: {output_model}")
        print(f"   æ ‡ç­¾å·²ä¿å­˜è‡³: {output_labels}")
        if result.stdout:
            print("ğŸ“ è®­ç»ƒè¾“å‡º:")
            print(result.stdout)
    else:
        raise Exception(f"åˆ†ç±»æ¨¡å‹è®­ç»ƒå¤±è´¥: {result.stderr}")


def train_sequence_model():
    """
    TODO: è§†é¢‘åºåˆ—æ¨¡å‹è®­ç»ƒå‡½æ•°
    
    é¢„ç•™æ¥å£ï¼Œæœªæ¥å®ç° LSTM/Transformer ç­‰åºåˆ—æ¨¡å‹è®­ç»ƒ
    """
    print("ğŸ¬ è§†é¢‘æ¨¡å‹è®­ç»ƒåŠŸèƒ½å·²é¢„ç•™ï¼ˆæœªå¯ç”¨ï¼‰")
    print("   TODO: å®ç°åŸºäºè§†é¢‘åºåˆ—çš„å§¿åŠ¿è¯„åˆ†æ¨¡å‹")
    print("   - è¾“å…¥: è§†é¢‘å¸§åºåˆ—")
    print("   - è¾“å‡º: æ—¶åºè¯„åˆ†æ¨¡å‹")
    print("   - æŠ€æœ¯æ ˆ: LSTM / Transformer / 3D-CNN")


def train_all():
    """
    ç»Ÿä¸€è®­ç»ƒæ‰€æœ‰æ¨¡å‹çš„ä¸»å‡½æ•°
    """
    print("=" * 60)
    print("ğŸš€ å¼€å§‹ç»Ÿä¸€æ¨¡å‹è®­ç»ƒæµç¨‹")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {LOG_FILE}")
    print("=" * 60)
    
    # è®°å½•æˆåŠŸå’Œå¤±è´¥çš„ä»»åŠ¡
    results = {
        "success": [],
        "failed": []
    }
    
    try:
        # 1. è¯„åˆ†æ¨¡å‹è®­ç»ƒ
        print("\n" + "="*60)
        print("ğŸ§˜ å¼€å§‹è¯„åˆ†æ¨¡å‹è®­ç»ƒ...")
        print("="*60)
        
        try:
            if train_from_dataset is None:
                raise ImportError("train_from_dataset å‡½æ•°ä¸å¯ç”¨")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs("models/score", exist_ok=True)
            
            # è°ƒç”¨è¯„åˆ†æ¨¡å‹è®­ç»ƒ
            train_from_dataset(
                dataset_dir="dataset/train",
                model_out="models/score/score_model.h5",
                epochs=2,  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
                batch_size=16,
                workers=4,
                learning_rate=0.001,
                validation_split=0.1,
                use_multi_head=False,
                mode='image_classification',
                plots_dir="training_plots/score"
            )
            
            print("âœ… è¯„åˆ†æ¨¡å‹è®­ç»ƒæˆåŠŸï¼")
            results["success"].append("è¯„åˆ†æ¨¡å‹")
            
        except Exception as e:
            print(f"âŒ è¯„åˆ†æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")
            results["failed"].append(("è¯„åˆ†æ¨¡å‹", str(e)))
        
        # 2. åˆ†ç±»æ¨¡å‹è®­ç»ƒ
        print("\n" + "="*60)
        print("ğŸ§  å¼€å§‹åˆ†ç±»æ¨¡å‹è®­ç»ƒ...")
        print("="*60)
        
        try:
            train_classifier_model(
                input_dir="dataset/classify",
                output_model="models/classify/classify_model.h5",
                output_labels="models/classify/class_labels.txt",
                epochs=15,
                batch_size=32
            )
            results["success"].append("åˆ†ç±»æ¨¡å‹")
            
        except Exception as e:
            print(f"âŒ åˆ†ç±»æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")
            results["failed"].append(("åˆ†ç±»æ¨¡å‹", str(e)))
        
        # 3. è§†é¢‘æ¨¡å‹è®­ç»ƒï¼ˆé¢„ç•™ï¼‰
        print("\n" + "="*60)
        try:
            train_sequence_model()
            # ç”±äºæ˜¯é¢„ç•™åŠŸèƒ½ï¼Œä¸è®¡å…¥ç»“æœ
        except Exception as e:
            print(f"âŒ è§†é¢‘æ¨¡å‹åŠŸèƒ½é”™è¯¯: {str(e)}")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸ è®­ç»ƒè¢«æ‰‹åŠ¨ä¸­æ–­ï¼")
        print("=" * 60)
        sys.stdout = tee.terminal  # æ¢å¤æ ‡å‡†è¾“å‡º
        tee.close()
        sys.exit(130)  # æ ‡å‡†çš„ KeyboardInterrupt é€€å‡ºç 
    
    # æ‰“å°æœ€ç»ˆç»“æœæ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š è®­ç»ƒç»“æœæ€»ç»“")
    print("="*60)
    
    if results["success"]:
        print(f"âœ… æˆåŠŸè®­ç»ƒçš„æ¨¡å‹ ({len(results['success'])}ä¸ª):")
        for model in results["success"]:
            print(f"   - {model}")
    
    if results["failed"]:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥çš„æ¨¡å‹ ({len(results['failed'])}ä¸ª):")
        for model, error in results["failed"]:
            print(f"   - {model}: {error}")
    
    print("\n" + "="*60)
    print(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if not results["failed"]:
        print("ğŸ‰ âœ… æ‰€æœ‰è®­ç»ƒä»»åŠ¡å®Œæˆï¼")
    else:
        print(f"âš ï¸ éƒ¨åˆ†ä»»åŠ¡å®Œæˆï¼æˆåŠŸ: {len(results['success'])}, å¤±è´¥: {len(results['failed'])}")
    print("="*60)
    
    # è¿”å›æ˜¯å¦å…¨éƒ¨æˆåŠŸ
    return len(results["failed"]) == 0


def main():
    """
    è„šæœ¬å…¥å£ç‚¹
    """
    try:
        # æ£€æŸ¥æ•°æ®å‡†å¤‡æƒ…å†µ
        print("ğŸ” æ£€æŸ¥è®­ç»ƒæ•°æ®å‡†å¤‡æƒ…å†µ...")
        
        # æ£€æŸ¥å¿…è¦çš„ç›®å½•
        required_dirs = ["dataset/train", "dataset/classify"]
        missing_dirs = []
        total_imgs = 0
        
        for dir_path in required_dirs:
            if not os.path.exists(dir_path):
                missing_dirs.append(dir_path)
            else:
                # ä¼˜åŒ–ï¼šä½¿ç”¨ç”Ÿæˆå™¨ç»Ÿè®¡ï¼Œé¿å…åˆ›å»ºåˆ—è¡¨
                count = sum(1 for p in Path(dir_path).rglob("*") 
                           if p.suffix.lower() in {'.jpg', '.jpeg', '.png'})
                print(f"âœ… {dir_path}: {count} å¼ å›¾ç‰‡")
                total_imgs += count
        
        if not missing_dirs:
            print(f"ğŸ“Š è®­ç»ƒæ€»å›¾ç‰‡æ•°: {total_imgs}")
        
        if missing_dirs:
            print(f"\nâŒ ç¼ºå°‘å¿…è¦çš„æ•°æ®ç›®å½•: {', '.join(missing_dirs)}")
            print("ğŸ’¡ æç¤ºï¼šè¯·å…ˆè¿è¡Œ prepare_training_data.py å‡†å¤‡è®­ç»ƒæ•°æ®")
            
            # è¯¢é—®æ˜¯å¦è‡ªåŠ¨å‡†å¤‡æ•°æ®
            response = input("\næ˜¯å¦è‡ªåŠ¨å‡†å¤‡è®­ç»ƒæ•°æ®ï¼Ÿ(y/N): ").strip().lower()
            if response == 'y':
                print("\nğŸš€ æ­£åœ¨å‡†å¤‡è®­ç»ƒæ•°æ®...")
                result = subprocess.run([sys.executable, "prepare_training_data.py"], 
                                      capture_output=True, text=True)
                if result.returncode != 0:
                    print(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {result.stderr}")
                    return 1
                else:
                    print("âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
                    if result.stdout:
                        print("ğŸ“ å‡†å¤‡è¿‡ç¨‹è¾“å‡º:")
                        print(result.stdout)
                    
                    # é‡æ–°ç»Ÿè®¡å›¾ç‰‡æ•°é‡
                    print("\nğŸ“Š é‡æ–°ç»Ÿè®¡è®­ç»ƒæ•°æ®...")
                    total_imgs = 0
                    for dir_path in required_dirs:
                        count = sum(1 for p in Path(dir_path).rglob("*") 
                                   if p.suffix.lower() in {'.jpg', '.jpeg', '.png'})
                        print(f"âœ… {dir_path}: {count} å¼ å›¾ç‰‡")
                        total_imgs += count
                    print(f"ğŸ“Š è®­ç»ƒæ€»å›¾ç‰‡æ•°: {total_imgs}")
            else:
                return 1
        
        # å¼€å§‹è®­ç»ƒ
        success = train_all()
        
        # è¿”å›é€‚å½“çš„é€€å‡ºç 
        return 0 if success else 1
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç¨‹åºè¢«æ‰‹åŠ¨ä¸­æ–­ï¼")
        return 130
    
    finally:
        # æ¢å¤æ ‡å‡†è¾“å‡ºå¹¶å…³é—­æ—¥å¿—æ–‡ä»¶
        if sys.stdout != sys.__stdout__:
            sys.stdout = tee.terminal
            tee.close()
            print(f"\nğŸ“ å®Œæ•´æ—¥å¿—å·²ä¿å­˜è‡³: {LOG_FILE}")


if __name__ == "__main__":
    sys.exit(main())